<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <script type="application/ld+json">

{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "基于搜狗新闻语料的文本分类",
  
  "image": "//cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/gallery/u/unsplash-mountain-alpine.jpg",
  
  "datePublished": "2019-05-22T20:35:48+08:00",
  "dateModified": "2019-05-22T20:35:48+08:00",
  "author": {
    "@type": "Person",
    "name": "aaron",
    
    "image": "https://cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/icons/plane-icon.png"
    
  },
  "mainEntityOfPage": { 
    "@type": "WebPage",
    "@id": "https:\/\/lijqhs.github.io\/2019\/05\/text-classification-scikit-learn\/" 
  },
  "publisher": {
    "@type": "Organization",
    "name": "aaron's notes",
    
    "logo": {
      "@type": "ImageObject",
      "url": "https://cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/icons/plane-icon.png"
    }
    
  },
  "description": "文本分类（Text Classification）是自然语言处理中的一个重要应用技术，根据文档的内容或主题，自动识别文档所属的预先定义的类别标签。\n",
  "keywords": []
}

</script>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.98.0 with theme Tranquilpeak 0.5.3-BETA">
<meta name="author" content="aaron">
<meta name="keywords" content="">
<meta name="description" content="文本分类（Text Classification）是自然语言处理中的一个重要应用技术，根据文档的内容或主题，自动识别文档所属的预先定义的类别标签。">


<meta property="og:description" content="文本分类（Text Classification）是自然语言处理中的一个重要应用技术，根据文档的内容或主题，自动识别文档所属的预先定义的类别标签。">
<meta property="og:type" content="article">
<meta property="og:title" content="基于搜狗新闻语料的文本分类">
<meta name="twitter:title" content="基于搜狗新闻语料的文本分类">
<meta property="og:url" content="https://lijqhs.github.io/2019/05/text-classification-scikit-learn/">
<meta property="twitter:url" content="https://lijqhs.github.io/2019/05/text-classification-scikit-learn/">
<meta property="og:site_name" content="aaron&#39;s notes">
<meta property="og:description" content="文本分类（Text Classification）是自然语言处理中的一个重要应用技术，根据文档的内容或主题，自动识别文档所属的预先定义的类别标签。">
<meta name="twitter:description" content="文本分类（Text Classification）是自然语言处理中的一个重要应用技术，根据文档的内容或主题，自动识别文档所属的预先定义的类别标签。">
<meta property="og:locale" content="en-us">

  
    <meta property="article:published_time" content="2019-05-22T20:35:48">
  
  
    <meta property="article:modified_time" content="2019-05-22T20:35:48">
  
  
  
    
      <meta property="article:section" content="data science">
    
  
  
    
      <meta property="article:tag" content="nlp">
    
      <meta property="article:tag" content="text classification">
    
      <meta property="article:tag" content="scikit-learn">
    
      <meta property="article:tag" content="machine learning">
    
      <meta property="article:tag" content="tf-idf">
    
      <meta property="article:tag" content="python">
    
  


<meta name="twitter:card" content="summary">

  <meta name="twitter:site" content="@jiaqingli">


  <meta name="twitter:creator" content="@jiaqingli">






  <meta property="og:image" content="https://cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/icons/plane-icon.png">
  <meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/icons/plane-icon.png">




  <meta property="og:image" content="//cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/gallery/u/unsplash-mountain-alpine.jpg">
  <meta property="twitter:image" content="//cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/gallery/u/unsplash-mountain-alpine.jpg">


  <meta property="og:image" content="//cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/gallery/u/unsplash-mountain-alpine.jpg">
  <meta property="twitter:image" content="//cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/gallery/u/unsplash-mountain-alpine.jpg">


    <title>基于搜狗新闻语料的文本分类</title>

    <link rel="icon" href="https://cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/icons/plane-icon.png">
    

    

    <link rel="canonical" href="https://lijqhs.github.io/2019/05/text-classification-scikit-learn/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha512-H9jrZiiopUdsLpg94A333EfumgUBpO9MdbxStdeITo+KEIMaNfHNvwyjjDJb+ERPaRS6DpyRlKbvPUasNItRyw==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    
    
    
    <link rel="stylesheet" href="https://lijqhs.github.io/css/style-h6ccsoet3mzkbb0wngshlfbaweimexgqcxj0h5hu4h82olsdzz6wmqdkajm.min.css" />
    
    

    
      
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6F8KMZN49C"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-6F8KMZN49C', { 'anonymize_ip': false });
}
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://lijqhs.github.io/" aria-label="Go to homepage">aaron&#39;s notes</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://lijqhs.github.io/#about" aria-label="Open the link: /#about">
    
    
    
      
        <img class="header-picture" src="https://cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/icons/plane-icon.png" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://lijqhs.github.io/#about" aria-label="Read more about the author">
          <img class="sidebar-profile-picture" src="https://cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/icons/plane-icon.png" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">aaron</h4>
        
          <h5 class="sidebar-profile-bio">random notes</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://lijqhs.github.io/" title="Home">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://lijqhs.github.io/categories" title="Categories">
    
      <i class="sidebar-button-icon fas fa-lg fa-bookmark" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://lijqhs.github.io/tags" title="Tags">
    
      <i class="sidebar-button-icon fas fa-lg fa-tags" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://lijqhs.github.io/archives" title="Archives">
    
      <i class="sidebar-button-icon fas fa-lg fa-archive" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://lijqhs.github.io/#about" title="About">
    
      <i class="sidebar-button-icon fas fa-lg fa-question" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/lijqhs" target="_blank" rel="noopener" title="GitHub">
    
      <i class="sidebar-button-icon fab fa-lg fa-github" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://lijqhs.github.io/algorithms-notes" title="Algo Notes">
    
      <i class="sidebar-button-icon fas fa-lg fa-archive" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Algo Notes</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://lijqhs.github.io/deeplearning-notes" title="DL Notes">
    
      <i class="sidebar-button-icon fas fa-lg fa-archive" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">DL Notes</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://lijqhs.github.io/data-science-ibm" title="DS Notes">
    
      <i class="sidebar-button-icon fas fa-lg fa-tags" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">DS Notes</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://lijqhs.github.io/leetcode" title="LeetCoding">
    
      <i class="sidebar-button-icon fas fa-lg fa-bookmark" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">LeetCoding</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://lijqhs.github.io/index.xml" title="RSS">
    
      <i class="sidebar-button-icon fas fa-lg fa-rss" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      
  <div class="post-header-cover
              text-left
              "
       style="background-image:url('//cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/gallery/u/unsplash-mountain-alpine.jpg')"
       data-behavior="4">
    
      <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title">
      基于搜狗新闻语料的文本分类
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time datetime="2019-05-22T20:35:48&#43;08:00">
        
  May 22, 2019

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="https://lijqhs.github.io/categories/data-science">data science</a>
    
  

  </div>

</div>
    
  </div>


      <div id="main" data-behavior="4"
        class="hasCover
               hasCoverMetaIn
               ">
        <article class="post" id="top">
          
          
          <div class="post-content markdown">
            <div class="main-content-wrap">
              <p>文本分类（Text Classification）是自然语言处理中的一个重要应用技术，根据文档的内容或主题，自动识别文档所属的预先定义的类别标签。</p>
<p>文本分类是很多应用场景的基础，比如垃圾邮件识别，舆情分析，情感识别，新闻自动分类，智能客服机器人的知识库分类等等。本文用标注好的搜狗新闻语料，基于scikit-learn机器学习Python库，将文本分类的完整过程实现一遍。本文代码放在了<a href="https://github.com/lijqhs/text-classification-cn">GitHub</a>上。</p>
<h1 id="table-of-contents">Table of Contents</h1>
<nav id="TableOfContents">
  <ul>
    <li><a href="#1-语料预处理">1. 语料预处理</a></li>
    <li><a href="#2-生成训练集和测试集">2. 生成训练集和测试集</a>
      <ul>
        <li><a href="#中文分词">中文分词</a></li>
        <li><a href="#生成数据集">生成数据集</a></li>
        <li><a href="#词云显示">词云显示</a></li>
      </ul>
    </li>
    <li><a href="#3-文本特征提取tf-idf">3. 文本特征提取:TF-IDF</a></li>
    <li><a href="#4-构建分类器">4. 构建分类器</a>
      <ul>
        <li><a href="#benchmark-朴素贝叶斯分类器">Benchmark: 朴素贝叶斯分类器</a></li>
        <li><a href="#对新文本应用分类">对新文本应用分类</a></li>
        <li><a href="#使用pipeline更方便">使用Pipeline更方便</a></li>
      </ul>
    </li>
    <li><a href="#5-分类器的评估">5. 分类器的评估</a>
      <ul>
        <li><a href="#构建logistic-regression分类器">构建Logistic Regression分类器</a></li>
        <li><a href="#构建svm分类器">构建SVM分类器</a></li>
      </ul>
    </li>
    <li><a href="#6-参考资料">6. 参考资料</a></li>
  </ul>
</nav>

<h2 id="1-语料预处理">1. 语料预处理</h2>
<p>首先加载所有需要用到的Python库</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> shutil
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jieba
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np 
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> wordcloud <span style="color:#f92672">import</span> WordCloud
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">%</span>matplotlib inline
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.pipeline <span style="color:#f92672">import</span> Pipeline
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> TfidfVectorizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.naive_bayes <span style="color:#f92672">import</span> MultinomialNB
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression, SGDClassifier
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> classification_report, confusion_matrix
</span></span></code></pre></div><p>定义搜狗新闻文本标签的名称，类似<code>C000008</code>这样的标签是语料的子目录，在网上搜到标签对应的新闻类别，为了便于理解，定义了这个映射词典，并保留原有编号信息。在网上搜索下载<code>搜狗分类新闻.20061127.zip</code>语料并解压至<code>CN_Corpus</code>目录下，解压之后目录结构为：</p>
<pre tabindex="0"><code>CN_Corpus
└─SogouC.reduced
    └─Reduced
        ├─C000008
        ├─C000010
        ├─C000013
        ├─C000014
        ├─C000016
        ├─C000020
        ├─C000022
        ├─C000023
        └─C000024
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>category_labels <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;C000008&#39;</span>: <span style="color:#e6db74">&#39;_08_Finance&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;C000010&#39;</span>: <span style="color:#e6db74">&#39;_10_IT&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;C000013&#39;</span>: <span style="color:#e6db74">&#39;_13_Health&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;C000014&#39;</span>: <span style="color:#e6db74">&#39;_14_Sports&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;C000016&#39;</span>: <span style="color:#e6db74">&#39;_16_Travel&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;C000020&#39;</span>: <span style="color:#e6db74">&#39;_20_Education&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;C000022&#39;</span>: <span style="color:#e6db74">&#39;_22_Recruit&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;C000023&#39;</span>: <span style="color:#e6db74">&#39;_23_Culture&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;C000024&#39;</span>: <span style="color:#e6db74">&#39;_24_Military&#39;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>下面进行语料的切分，将每个类别的前80%作为训练语料，后20%作为测试语料。切分完之后的语料目录如下：</p>
<pre tabindex="0"><code>data
├─test
│  ├─_08_Finance
│  ├─_10_IT
│  ├─_13_Health
│  ├─_14_Sports
│  ├─_16_Travel
│  ├─_20_Education
│  ├─_22_Recruit
│  ├─_23_Culture
│  └─_24_Military
└─train
    ├─_08_Finance
    ├─_10_IT
    ├─_13_Health
    ├─_14_Sports
    ├─_16_Travel
    ├─_20_Education
    ├─_22_Recruit
    ├─_23_Culture
    └─_24_Military
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">split_corpus</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># original data directory</span>
</span></span><span style="display:flex;"><span>    original_dataset_dir <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./CN_Corpus/SogouC.reduced/Reduced&#39;</span>
</span></span><span style="display:flex;"><span>    base_dir <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;data/&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(base_dir)):
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#39;`data` seems already exist.&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># make new folders</span>
</span></span><span style="display:flex;"><span>    os<span style="color:#f92672">.</span>mkdir(base_dir)
</span></span><span style="display:flex;"><span>    train_dir <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(base_dir, <span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>    os<span style="color:#f92672">.</span>mkdir(train_dir)
</span></span><span style="display:flex;"><span>    test_dir <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(base_dir, <span style="color:#e6db74">&#39;test&#39;</span>)
</span></span><span style="display:flex;"><span>    os<span style="color:#f92672">.</span>mkdir(test_dir)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># split corpus</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> cate <span style="color:#f92672">in</span> os<span style="color:#f92672">.</span>listdir(original_dataset_dir):
</span></span><span style="display:flex;"><span>        cate_dir <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(original_dataset_dir, cate)
</span></span><span style="display:flex;"><span>        file_list <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>listdir(cate_dir)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;cate: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, len: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(cate, len(file_list)))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># train data</span>
</span></span><span style="display:flex;"><span>        fnames <span style="color:#f92672">=</span> file_list[:<span style="color:#ae81ff">1500</span>] 
</span></span><span style="display:flex;"><span>        dst_dir <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(train_dir, category_labels[cate])
</span></span><span style="display:flex;"><span>        os<span style="color:#f92672">.</span>mkdir(dst_dir)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;dst_dir: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, len: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(dst_dir, len(fnames)))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> fname <span style="color:#f92672">in</span> fnames:
</span></span><span style="display:flex;"><span>            src <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(cate_dir, fname)
</span></span><span style="display:flex;"><span>            dst <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(dst_dir, fname)
</span></span><span style="display:flex;"><span>            shutil<span style="color:#f92672">.</span>copyfile(src, dst)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># test data</span>
</span></span><span style="display:flex;"><span>        fnames <span style="color:#f92672">=</span> file_list[<span style="color:#ae81ff">1500</span>:] 
</span></span><span style="display:flex;"><span>        dst_dir <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(test_dir, category_labels[cate])
</span></span><span style="display:flex;"><span>        os<span style="color:#f92672">.</span>mkdir(dst_dir)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;dst_dir: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, len: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(dst_dir, len(fnames)))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> fname <span style="color:#f92672">in</span> fnames:
</span></span><span style="display:flex;"><span>            src <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(cate_dir, fname)
</span></span><span style="display:flex;"><span>            dst <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(dst_dir, fname)
</span></span><span style="display:flex;"><span>            shutil<span style="color:#f92672">.</span>copyfile(src, dst)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;Corpus split DONE.&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>split_corpus()
</span></span></code></pre></div><pre><code>cate: C000008, len: 1990
dst_dir: data/train/_08_Finance, len: 1500
dst_dir: data/test/_08_Finance, len: 490
cate: C000010, len: 1990
dst_dir: data/train/_10_IT, len: 1500
dst_dir: data/test/_10_IT, len: 490
cate: C000013, len: 1990
dst_dir: data/train/_13_Health, len: 1500
dst_dir: data/test/_13_Health, len: 490
cate: C000014, len: 1990
dst_dir: data/train/_14_Sports, len: 1500
dst_dir: data/test/_14_Sports, len: 490
cate: C000016, len: 1990
dst_dir: data/train/_16_Travel, len: 1500
dst_dir: data/test/_16_Travel, len: 490
cate: C000020, len: 1990
dst_dir: data/train/_20_Education, len: 1500
dst_dir: data/test/_20_Education, len: 490
cate: C000022, len: 1990
dst_dir: data/train/_22_Recruit, len: 1500
dst_dir: data/test/_22_Recruit, len: 490
cate: C000023, len: 1990
dst_dir: data/train/_23_Culture, len: 1500
dst_dir: data/test/_23_Culture, len: 490
cate: C000024, len: 1990
dst_dir: data/train/_24_Military, len: 1500
dst_dir: data/test/_24_Military, len: 490
Corpus split DONE.
</code></pre>
<h2 id="2-生成训练集和测试集">2. 生成训练集和测试集</h2>
<h3 id="中文分词">中文分词</h3>
<p>定义一个分词预处理函数，采用<code>jieba</code>分词工具，主要去掉对文本分类无用的标点符号和数字，输入为新闻文本，输出为分词之后并用空格连接的文本。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>token <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;[0-9\s+\.\!\/_,$%^*()?;；：【】+</span><span style="color:#ae81ff">\&#34;\&#39;</span><span style="color:#e6db74">\[\]</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">]+|[+——！，;:。？《》、~@#￥%……&amp;*（）“”.=-]+&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">preprocess</span>(text):
</span></span><span style="display:flex;"><span>    text1 <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">&#39;&amp;nbsp&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)
</span></span><span style="display:flex;"><span>    str_no_punctuation <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(token, <span style="color:#e6db74">&#39; &#39;</span>, text1)  <span style="color:#75715e"># 去掉标点</span>
</span></span><span style="display:flex;"><span>    text_list <span style="color:#f92672">=</span> list(jieba<span style="color:#f92672">.</span>cut(str_no_punctuation))   <span style="color:#75715e"># 分词列表</span>
</span></span><span style="display:flex;"><span>    text_list <span style="color:#f92672">=</span> [item <span style="color:#66d9ef">for</span> item <span style="color:#f92672">in</span> text_list <span style="color:#66d9ef">if</span> item <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#39; &#39;</span>] <span style="color:#75715e"># 去掉空格</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(text_list)
</span></span></code></pre></div><h3 id="生成数据集">生成数据集</h3>
<p>从上面切分好的语料目录中读取文本并进行分词预处理，输出：训练语料数据(<code>X_train_data</code>)、训练语料标签(<code>y_train</code>)、测试语料数据(<code>X_test_data</code>)、测试语料标签(<code>y_test</code>)。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_datasets</span>():
</span></span><span style="display:flex;"><span>    base_dir <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;data/&#39;</span>
</span></span><span style="display:flex;"><span>    X_data <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;train&#39;</span>:[], <span style="color:#e6db74">&#39;test&#39;</span>:[]}
</span></span><span style="display:flex;"><span>    y <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;train&#39;</span>:[], <span style="color:#e6db74">&#39;test&#39;</span>:[]}
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> type_name <span style="color:#f92672">in</span> [<span style="color:#e6db74">&#39;train&#39;</span>, <span style="color:#e6db74">&#39;test&#39;</span>]:
</span></span><span style="display:flex;"><span>        corpus_dir <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(base_dir, type_name)
</span></span><span style="display:flex;"><span>        corpus_list <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> label <span style="color:#f92672">in</span> os<span style="color:#f92672">.</span>listdir(corpus_dir):
</span></span><span style="display:flex;"><span>            label_dir <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(corpus_dir, label)
</span></span><span style="display:flex;"><span>            file_list <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>listdir(label_dir)
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#34;label: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, len: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(label, len(file_list)))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> fname <span style="color:#f92672">in</span> file_list:
</span></span><span style="display:flex;"><span>                file_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(label_dir, fname)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">with</span> open(file_path, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;gb2312&#39;</span>, errors<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ignore&#39;</span>) <span style="color:#66d9ef">as</span> text_file:
</span></span><span style="display:flex;"><span>                    text_content <span style="color:#f92672">=</span> preprocess(text_file<span style="color:#f92672">.</span>read())
</span></span><span style="display:flex;"><span>                X_data[type_name]<span style="color:#f92672">.</span>append(text_content)
</span></span><span style="display:flex;"><span>                y[type_name]<span style="color:#f92672">.</span>append(label)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> corpus len: </span><span style="color:#e6db74">{}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(type_name, len(X_data[type_name])))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> X_data[<span style="color:#e6db74">&#39;train&#39;</span>], y[<span style="color:#e6db74">&#39;train&#39;</span>], X_data[<span style="color:#e6db74">&#39;test&#39;</span>], y[<span style="color:#e6db74">&#39;test&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train_data, y_train, X_test_data, y_test <span style="color:#f92672">=</span> load_datasets()
</span></span></code></pre></div><pre><code>label: _08_Finance, len: 1500
label: _10_IT, len: 1500
label: _13_Health, len: 1500
label: _14_Sports, len: 1500
label: _16_Travel, len: 1500
label: _20_Education, len: 1500
label: _22_Recruit, len: 1500
label: _23_Culture, len: 1500
label: _24_Military, len: 1500
train corpus len: 13500

label: _08_Finance, len: 490
label: _10_IT, len: 490
label: _13_Health, len: 490
label: _14_Sports, len: 490
label: _16_Travel, len: 490
label: _20_Education, len: 490
label: _22_Recruit, len: 490
label: _23_Culture, len: 490
label: _24_Military, len: 490
test corpus len: 4410
</code></pre>
<p>数据集的形式如下：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X_train_data[<span style="color:#ae81ff">1000</span>]
</span></span></code></pre></div><pre><code>'新华网 上海 月 日电 记者 黄庭钧 继 日 人民币 兑 美元 中间价 突破 关口 创 历史 新高 后 日 人民币 兑 美元汇率 继续 攀升 中国外汇交易中心 日 公布 的 中间价 为 再刷 历史 新高 大有 逼近 和 突破 心理 关口 之势 据 兴业银行 资金 营运 中心 交易员 余屹 介绍 人民币 兑 美元汇率 日 走势 继续 表现 强劲 竞价 交易 以 开盘 后 最低 曾 回到 最高 则 触及 距 关口 仅 一步之遥 收报 而 询价 交易 亦 表现 不俗 以 开盘 后 曾经 走低 到 最高 仅触 到 截至 时 分 报收 虽然 全日 波幅 较窄 但 均 在 下方 有 跃跃欲试 关口 之 态势 完'
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>y_train[<span style="color:#ae81ff">1000</span>]
</span></span></code></pre></div><pre><code>'_08_Finance'
</code></pre>
<h3 id="词云显示">词云显示</h3>
<p>这里插一个与文本分类无关的步骤，用WordCloud展示文本的词频信息，直观看一下文本关键词信息，生成的词云图片可以让人一目了然。如果让人来进行分类，扫一眼词云就可以在很短时间内做出分类判断，比阅读原始文本要快的多，其原理就是利用了文本中的高频词信息，频率高的词（去除停用词之后）比较能代表文本的主旨信息，其实后面的分类过程大概就是这个思路。WordCloud默认不显示中文字体，会显示成方块，可以在网上下载字体文件simhei.ttf，放在当前目录下即可。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>wordcloud <span style="color:#f92672">=</span> WordCloud(scale<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>,
</span></span><span style="display:flex;"><span>                      font_path<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;simhei.ttf&#39;</span>,
</span></span><span style="display:flex;"><span>                      background_color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;white&#39;</span>,
</span></span><span style="display:flex;"><span>                      max_words <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>,
</span></span><span style="display:flex;"><span>                      max_font_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">60</span>,
</span></span><span style="display:flex;"><span>                      random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)<span style="color:#f92672">.</span>generate(X_train_data[<span style="color:#ae81ff">1000</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>imshow(wordcloud, interpolation<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bilinear&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;off&#39;</span>)
</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/lijqhs/cdn@1.0/img/post/wordcloud.png" alt="png"></p>
<h2 id="3-文本特征提取tf-idf">3. 文本特征提取:TF-IDF</h2>
<p>这个步骤将文档信息，也即每篇新闻被分好词之后的词集合，转为为基于词频-你文档词频（TF-IDF）的向量，向量的每个元素都是对应于某个词在这个文档中的TF-IDF值，在不同文档中，同一词的TF-IDF是不一样的。所有文档的TF-IDF向量堆放在一起就组成了一个TF-IDF矩阵。注意到这里应该包含了除停用词之外的所有词的TF-IDF值，词的个数构成了向量的维度。</p>
<p>用<code>TfidfVectorizer</code>将文档集合转为<code>TF-IDF</code>矩阵。注意到前面我们将文本做了分词并用空格隔开。如果是英文，本身就是空格隔开的，而英文的分词（Tokenizing）是包含在特征提取器中的，不需要分词这一步骤。下面我们在得到了分类器之后，使用新文本进行分类预测时，也是需要先做一下中文分词的。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>stopwords <span style="color:#f92672">=</span> open(<span style="color:#e6db74">&#39;dict/stop_words.txt&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>)<span style="color:#f92672">.</span>read()<span style="color:#f92672">.</span>split()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TF-IDF feature extraction</span>
</span></span><span style="display:flex;"><span>tfidf_vectorizer <span style="color:#f92672">=</span> TfidfVectorizer(stop_words<span style="color:#f92672">=</span>stopwords)
</span></span><span style="display:flex;"><span>X_train_tfidf <span style="color:#f92672">=</span> tfidf_vectorizer<span style="color:#f92672">.</span>fit_transform(X_train_data)
</span></span><span style="display:flex;"><span>words <span style="color:#f92672">=</span> tfidf_vectorizer<span style="color:#f92672">.</span>get_feature_names()
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X_train_tfidf<span style="color:#f92672">.</span>shape
</span></span></code></pre></div><pre><code>(13500, 223094)
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>len(words)
</span></span></code></pre></div><pre><code>223094
</code></pre>
<h2 id="4-构建分类器">4. 构建分类器</h2>
<h3 id="benchmark-朴素贝叶斯分类器">Benchmark: 朴素贝叶斯分类器</h3>
<p>得到了训练样本的文本特征，现在可以训练出一个分类器，以用来对新的新闻文本进行分类。<code>scikit-learn</code>中提供了多种分类器，其中<a href="https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes">朴素贝叶斯</a>是一个很好的基准，有多个版本的朴素贝叶斯分类器，其中<a href="https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes"><code>MultinomialNB</code></a>比较适合于文本分类。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>classifier <span style="color:#f92672">=</span> MultinomialNB()
</span></span><span style="display:flex;"><span>classifier<span style="color:#f92672">.</span>fit(X_train_tfidf, y_train)
</span></span></code></pre></div><pre><code>MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)
</code></pre>
<h3 id="对新文本应用分类">对新文本应用分类</h3>
<p>对新的文本需要进行分类，那么只需将上面的<code>tfidf_vectorizer</code>应用在新的文本上，调用<code>transform</code>方法而不是<code>fit_transform</code>，将新的文本转换为<code>TF-IDF</code>特征，然后再调用分类器的<code>predict</code>，得到分类。</p>
<p>下面新闻节选自腾讯新闻网，原文地址：</p>
<ul>
<li><a href="https://new.qq.com/omn/20190521/20190521A08M6V.html">周鸿祎金融梦，营收20亿元直逼趣店，净利润同比增340％</a></li>
<li><a href="https://new.qq.com/omn/20190503/20190503A03SIG.html">录取率低过5％的美国名校，为何“花钱”就能上？</a></li>
<li><a href="https://new.qq.com/omn/20190520/20190520A0D4LA.html">特朗普：伊朗对美军动武将会“灭亡”</a></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>news_lastest <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;360金融旗下产品有360借条、360小微贷、360分期。360借条是360金融的核心产品，是一款无抵押、纯线上消费信贷产品，为用户提供即时到账贷款服务（通俗可以理解为“现金贷”）用户借款主要用于消费支出。从收入构成来看，360金融主要有贷款便利服务费、贷后管理服务费、融资收入、其他服务收入等构成。财报披露，营收增长主要是由于贷款便利化服务费、贷款发放后服务费和其他与贷款发放量增加相关的服务费增加。&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;检方并未起诉全部涉嫌贿赂的家长，但起诉名单已有超过50人，耶鲁大学、斯坦福大学等录取率极低的名校涉案也让该事件受到了几乎全球的关注，该案甚至被称作美国“史上最大招生舞弊案”。&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;俄媒称，目前尚不清楚特朗普这一言论的指向性，因为近几日，伊朗官员们都在表达力图避免与美国发生军事冲突的意愿。5月19日早些时候，伊朗革命卫队司令侯赛因·萨拉米称，伊朗只想追求和平，但并不害怕与美国发生战争。萨拉米称，“我们（伊朗）和他们（美国）之间的区别在于，美国害怕发生战争，缺乏开战的意志。”&#34;</span>]
</span></span><span style="display:flex;"><span>X_new_data <span style="color:#f92672">=</span> [preprocess(doc) <span style="color:#66d9ef">for</span> doc <span style="color:#f92672">in</span> news_lastest]
</span></span><span style="display:flex;"><span>X_new_data
</span></span></code></pre></div><pre><code>['金融 旗下 产品 有 借条 小微贷 分期 借条 是 金融 的 核心 产品 是 一款 无 抵押 纯线 上 消费信贷 产品 为 用户 提供 即时 到 账 贷款 服务 通俗 可以 理解 为 现金 贷 用户 借款 主要 用于 消费 支出 从 收入 构成 来看 金融 主要 有 贷款 便利 服务费 贷后 管理 服务费 融资 收入 其他 服务收入 等 构成 财报 披露 营收 增长 主要 是 由于 贷款 便利化 服务费 贷款 发放 后 服务费 和 其他 与 贷款 发放量 增加 相关 的 服务费 增加',
 '检方 并未 起诉 全部 涉嫌 贿赂 的 家长 但 起诉 名单 已有 超过 人 耶鲁大学 斯坦福大学 等 录取率 极低 的 名校 涉案 也 让 该 事件 受到 了 几乎 全球 的 关注 该案 甚至 被称作 美国 史上 最大 招生 舞弊案',
 '俄媒称 目前 尚 不 清楚 特朗普 这一 言论 的 指向性 因为 近几日 伊朗 官员 们 都 在 表达 力图 避免 与 美国 发生 军事冲突 的 意愿 月 日 早些时候 伊朗 革命 卫队 司令 侯赛因 · 萨拉米 称 伊朗 只想 追求 和平 但 并 不 害怕 与 美国 发生 战争 萨拉米 称 我们 伊朗 和 他们 美国 之间 的 区别 在于 美国 害怕 发生 战争 缺乏 开战 的 意志']
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X_new_tfidf <span style="color:#f92672">=</span> tfidf_vectorizer<span style="color:#f92672">.</span>transform(X_new_data)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>predicted  <span style="color:#f92672">=</span> classifier<span style="color:#f92672">.</span>predict(X_new_tfidf)
</span></span><span style="display:flex;"><span>predicted
</span></span></code></pre></div><pre><code>array(['_08_Finance', '_20_Education', '_24_Military'], dtype='&lt;U13')
</code></pre>
<p>可以看到上面对新的文本的分类结果是正确的。</p>
<h3 id="使用pipeline更方便">使用Pipeline更方便</h3>
<p><code>scikit-learn</code>提供了一个<code>Pipeline</code>工具，可以将上面从特征提取到分类器的训练这些步骤串起来，以方便调用。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>text_clf <span style="color:#f92672">=</span> Pipeline([
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#39;vect&#39;</span>, TfidfVectorizer()),
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#39;clf&#39;</span>, MultinomialNB()),
</span></span><span style="display:flex;"><span>])
</span></span></code></pre></div><p>使用Pipeline训练分类器，这里直接使用原始数据，而不是特征提取之后的TF-IDF数据。因为特征提取包含在Pipeline中。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>text_clf<span style="color:#f92672">.</span>fit(X_train_data, y_train)
</span></span></code></pre></div><pre><code>Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=&lt;class 'numpy.int64'&gt;, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
  ...rue,
        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])
</code></pre>
<p>使用Pipeline对上述新的新闻文本进行分类：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>text_clf<span style="color:#f92672">.</span>predict(X_new_data)
</span></span></code></pre></div><pre><code>array(['_08_Finance', '_20_Education', '_24_Military'], dtype='&lt;U13')
</code></pre>
<h2 id="5-分类器的评估">5. 分类器的评估</h2>
<p>有了分类器，以及知道了如何用分类器来对新的文本进行分类预测，那么我们可以用前面划分出来的测试集对这个分类器进行性能评估。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>predicted <span style="color:#f92672">=</span> text_clf<span style="color:#f92672">.</span>predict(X_test_data)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>np<span style="color:#f92672">.</span>mean(predicted <span style="color:#f92672">==</span> y_test)
</span></span></code></pre></div><pre><code>0.8435374149659864
</code></pre>
<p>OK，我们得到了84.35%的准确率，作为Benchmark，这个结果还不错。调用<code>classification_report</code>可以得到更详细的结果：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(classification_report(predicted, y_test))
</span></span></code></pre></div><pre><code>               precision    recall  f1-score   support

  _08_Finance       0.88      0.88      0.88       488
       _10_IT       0.72      0.87      0.79       403
   _13_Health       0.82      0.84      0.83       478
   _14_Sports       0.95      1.00      0.97       466
   _16_Travel       0.86      0.92      0.89       455
_20_Education       0.71      0.87      0.79       401
  _22_Recruit       0.91      0.65      0.76       690
  _23_Culture       0.80      0.77      0.79       513
 _24_Military       0.94      0.89      0.92       516

     accuracy                           0.84      4410
    macro avg       0.84      0.86      0.84      4410
 weighted avg       0.85      0.84      0.84      4410
</code></pre>
<p>再看一下混淆矩阵：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>confusion_matrix(predicted, y_test)
</span></span></code></pre></div><pre><code>array([[429,  12,  15,  10,   5,   3,   6,   4,   4],
       [ 20, 352,   6,   3,   5,   2,  10,   4,   1],
       [  3,  38, 403,   0,   6,  16,   5,   7,   0],
       [  0,   1,   0, 464,   0,   0,   0,   1,   0],
       [  5,  11,   0,   0, 419,   5,   2,  12,   1],
       [  4,  11,   5,   1,   2, 350,  13,  14,   1],
       [ 22,  21,  57,   8,  14,  87, 448,  32,   1],
       [  3,  25,   4,   4,  34,  23,   5, 394,  21],
       [  4,  19,   0,   0,   5,   4,   1,  22, 461]])
</code></pre>
<h3 id="构建logistic-regression分类器">构建Logistic Regression分类器</h3>
<p>让我们再试一下其他的分类器，比如<code>Logistic Regression</code>，训练新的分类器，代码也是非常简单：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>text_clf_lr <span style="color:#f92672">=</span> Pipeline([
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#39;vect&#39;</span>, TfidfVectorizer()),
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#39;clf&#39;</span>, LogisticRegression()),
</span></span><span style="display:flex;"><span>])
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>text_clf_lr<span style="color:#f92672">.</span>fit(X_train_data, y_train)
</span></span></code></pre></div><pre><code>Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=&lt;class 'numpy.int64'&gt;, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,
  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))])
</code></pre>
<p>对上面的新的腾讯新闻应用LR分类器，看看效果：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>text_clf_lr<span style="color:#f92672">.</span>predict(X_new_data)
</span></span></code></pre></div><pre><code>array(['_10_IT', '_10_IT', '_24_Military'], dtype='&lt;U13')
</code></pre>
<p>哎呀，好像不太行啊，居然有两个分错了耶。那么我们用测试集评估一下，看看结果：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>predicted_lr <span style="color:#f92672">=</span> text_clf_lr<span style="color:#f92672">.</span>predict(X_test_data)
</span></span><span style="display:flex;"><span>print(classification_report(predicted_lr, y_test))
</span></span></code></pre></div><pre><code>               precision    recall  f1-score   support

  _08_Finance       0.87      0.91      0.89       465
       _10_IT       0.77      0.86      0.81       440
   _13_Health       0.91      0.82      0.86       546
   _14_Sports       0.98      0.99      0.98       483
   _16_Travel       0.90      0.90      0.90       488
_20_Education       0.79      0.91      0.85       429
  _22_Recruit       0.86      0.85      0.85       495
  _23_Culture       0.86      0.75      0.80       556
 _24_Military       0.95      0.92      0.93       508

     accuracy                           0.88      4410
    macro avg       0.88      0.88      0.88      4410
 weighted avg       0.88      0.88      0.88      4410
</code></pre>
<p>最后测试结果还行嘛，比Benchmark分类器好了不少。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>confusion_matrix(predicted_lr, y_test)
</span></span></code></pre></div><pre><code>array([[425,  11,   7,   1,   2,   4,   9,   5,   1],
       [ 23, 377,   4,   3,   9,   3,  12,   7,   2],
       [  9,  41, 447,   0,   6,  23,  10,  10,   0],
       [  0,   2,   0, 478,   0,   1,   0,   1,   1],
       [  8,  12,   0,   0, 440,   8,   3,  16,   1],
       [  1,   6,   2,   0,   1, 389,  20,  10,   0],
       [  8,   7,  22,   1,   5,  26, 420,   6,   0],
       [ 11,  23,   8,   6,  24,  30,  15, 419,  20],
       [  5,  11,   0,   1,   3,   6,   1,  16, 465]])
</code></pre>
<h3 id="构建svm分类器">构建SVM分类器</h3>
<p>据说在传统机器学习中，SVM是做文本分类最好的工具。同样做一下跟上面LR一样的对比：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>text_clf_svm <span style="color:#f92672">=</span> Pipeline([
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#39;vect&#39;</span>, TfidfVectorizer()),
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#39;clf&#39;</span>, SGDClassifier(loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;hinge&#39;</span>, penalty<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l2&#39;</span>)),
</span></span><span style="display:flex;"><span>])
</span></span><span style="display:flex;"><span>text_clf_svm<span style="color:#f92672">.</span>fit(X_train_data, y_train)
</span></span><span style="display:flex;"><span>text_clf_svm<span style="color:#f92672">.</span>predict(X_new_data)
</span></span></code></pre></div><pre><code>array(['_08_Finance', '_10_IT', '_24_Military'], dtype='&lt;U13')
</code></pre>
<p>这次好一点，但还是有一个错了。看看测试集的效果，的确要比LR还要好一些。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>predicted_svm <span style="color:#f92672">=</span> text_clf_svm<span style="color:#f92672">.</span>predict(X_test_data)
</span></span><span style="display:flex;"><span>print(classification_report(predicted_svm, y_test))
</span></span></code></pre></div><pre><code>               precision    recall  f1-score   support

  _08_Finance       0.87      0.92      0.90       463
       _10_IT       0.78      0.85      0.81       446
   _13_Health       0.93      0.82      0.87       558
   _14_Sports       0.99      0.99      0.99       488
   _16_Travel       0.91      0.91      0.91       489
_20_Education       0.82      0.92      0.86       437
  _22_Recruit       0.89      0.85      0.87       513
  _23_Culture       0.85      0.83      0.84       503
 _24_Military       0.96      0.91      0.93       513

     accuracy                           0.89      4410
    macro avg       0.89      0.89      0.89      4410
 weighted avg       0.89      0.89      0.89      4410
</code></pre>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>confusion_matrix(predicted_svm, y_test)
</span></span></code></pre></div><pre><code>array([[428,  11,   5,   1,   5,   3,   5,   8,   0],
       [ 23, 382,   4,   0,   6,   8,  11,   7,   2],
       [  9,  39, 453,   0,   7,  19,  10,   9,   0],
       [  0,   1,   0, 485,   0,   2,   0,   1,   0],
       [  7,  14,   0,   0, 449,   7,   3,  14,   1],
       [  3,   7,   1,   1,   1, 403,  14,  15,   0],
       [ 12,   8,  22,   0,   4,  25, 437,   8,   0],
       [  4,  15,   5,   3,  15,  17,   9, 411,  19],
       [  4,  13,   0,   0,   3,   6,   1,  17, 468]])
</code></pre>
<p>本文代码地址：<a href="https://github.com/lijqhs/text-classification-cn">GitHub</a>.</p>
<h2 id="6-参考资料">6. 参考资料</h2>
<ul>
<li><a href="https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html">Scikit-learn Working With Text Data</a></li>
</ul>
              


            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="https://lijqhs.github.io/tags/nlp/">nlp</a>

  <a class="tag tag--primary tag--small" href="https://lijqhs.github.io/tags/text-classification/">text classification</a>

  <a class="tag tag--primary tag--small" href="https://lijqhs.github.io/tags/scikit-learn/">scikit-learn</a>

  <a class="tag tag--primary tag--small" href="https://lijqhs.github.io/tags/machine-learning/">machine learning</a>

  <a class="tag tag--primary tag--small" href="https://lijqhs.github.io/tags/tf-idf/">tf-idf</a>

  <a class="tag tag--primary tag--small" href="https://lijqhs.github.io/tags/python/">python</a>

                  </div>
                
              
            
            
<div class="post-actions-wrap">
  <nav >
    <ul class="post-actions post-action-nav">
      
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://lijqhs.github.io/2019/05/text-classification-pretrained-keras-cnn/" data-tooltip="基于预训练词向量模型的文本分类方法" aria-label="NEXT: 基于预训练词向量模型的文本分类方法">
          
              <i class="fa fa-angle-left"></i>
              <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
            </a>
        </li>
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://lijqhs.github.io/2019/03/git-quickstart/" data-tooltip="Git快速指南" aria-label="PREVIOUS: Git快速指南">
          
              <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
              <i class="fa fa-angle-right"></i>
            </a>
        </li>
      
    </ul>
  </nav>
<ul class="post-actions post-action-share" >
  
    <li class="post-action hide-lg hide-md hide-sm">
      <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
        <i class="fa fa-share-alt" aria-hidden="true"></i>
      </a>
    </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://lijqhs.github.io/2019/05/text-classification-scikit-learn/" title="Share on Facebook" aria-label="Share on Facebook">
          <i class="fab fa-facebook-square" aria-hidden="true"></i>
        </a>
      </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://lijqhs.github.io/2019/05/text-classification-scikit-learn/" title="Share on Twitter" aria-label="Share on Twitter">
          <i class="fab fa-twitter" aria-hidden="true"></i>
        </a>
      </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://www.linkedin.com/sharing/share-offsite/?url=https://lijqhs.github.io/2019/05/text-classification-scikit-learn/" title="Share on Linkedin" aria-label="Share on Linkedin">
          <i class="fab fa-linkedin" aria-hidden="true"></i>
        </a>
      </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://www.reddit.com/submit?url=https://lijqhs.github.io/2019/05/text-classification-scikit-learn/" title="Share on Reddit" aria-label="Share on Reddit">
          <i class="fab fa-reddit" aria-hidden="true"></i>
        </a>
      </li>
    
  
  
    <li class="post-action">
      <a class="post-action-btn btn btn--default" href="#disqus_thread" aria-label="Leave a comment">
        <i class="far fa-comment"></i>
      </a>
    </li>
  
  <li class="post-action">
    
      <a class="post-action-btn btn btn--default" href="#top" aria-label="Back to top">
      <i class="fa fa-arrow-up" aria-hidden="true"></i>
    
    </a>
  </li>
</ul>
</div>


            
  
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
    <script type="text/javascript">
      var disqus_config = function() {
        this.page.url = 'https:\/\/lijqhs.github.io\/2019\/05\/text-classification-scikit-learn\/';
        
          this.page.identifier = '\/2019\/05\/text-classification-scikit-learn\/'
        
      };
      (function() {
        
        
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
          document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
          return;
        }
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        var disqus_shortname = 'lijqhs';
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
  


          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2022 aaron. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
<div class="post-actions-wrap">
  <nav >
    <ul class="post-actions post-action-nav">
      
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://lijqhs.github.io/2019/05/text-classification-pretrained-keras-cnn/" data-tooltip="基于预训练词向量模型的文本分类方法" aria-label="NEXT: 基于预训练词向量模型的文本分类方法">
          
              <i class="fa fa-angle-left"></i>
              <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
            </a>
        </li>
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://lijqhs.github.io/2019/03/git-quickstart/" data-tooltip="Git快速指南" aria-label="PREVIOUS: Git快速指南">
          
              <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
              <i class="fa fa-angle-right"></i>
            </a>
        </li>
      
    </ul>
  </nav>
<ul class="post-actions post-action-share" >
  
    <li class="post-action hide-lg hide-md hide-sm">
      <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
        <i class="fa fa-share-alt" aria-hidden="true"></i>
      </a>
    </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://lijqhs.github.io/2019/05/text-classification-scikit-learn/" title="Share on Facebook" aria-label="Share on Facebook">
          <i class="fab fa-facebook-square" aria-hidden="true"></i>
        </a>
      </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://lijqhs.github.io/2019/05/text-classification-scikit-learn/" title="Share on Twitter" aria-label="Share on Twitter">
          <i class="fab fa-twitter" aria-hidden="true"></i>
        </a>
      </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://www.linkedin.com/sharing/share-offsite/?url=https://lijqhs.github.io/2019/05/text-classification-scikit-learn/" title="Share on Linkedin" aria-label="Share on Linkedin">
          <i class="fab fa-linkedin" aria-hidden="true"></i>
        </a>
      </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://www.reddit.com/submit?url=https://lijqhs.github.io/2019/05/text-classification-scikit-learn/" title="Share on Reddit" aria-label="Share on Reddit">
          <i class="fab fa-reddit" aria-hidden="true"></i>
        </a>
      </li>
    
  
  
    <li class="post-action">
      <a class="post-action-btn btn btn--default" href="#disqus_thread" aria-label="Leave a comment">
        <i class="far fa-comment"></i>
      </a>
    </li>
  
  <li class="post-action">
    
      <a class="post-action-btn btn btn--default" href="#top" aria-label="Back to top">
      <i class="fa fa-arrow-up" aria-hidden="true"></i>
    
    </a>
  </li>
</ul>
</div>


      </div>
      
<div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-times"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Flijqhs.github.io%2F2019%2F05%2Ftext-classification-scikit-learn%2F" aria-label="Share on Facebook">
          <i class="fab fa-facebook-square" aria-hidden="true"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https%3A%2F%2Flijqhs.github.io%2F2019%2F05%2Ftext-classification-scikit-learn%2F" aria-label="Share on Twitter">
          <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Flijqhs.github.io%2F2019%2F05%2Ftext-classification-scikit-learn%2F" aria-label="Share on Linkedin">
          <i class="fab fa-linkedin" aria-hidden="true"></i><span>Share on Linkedin</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.reddit.com/submit?url=https%3A%2F%2Flijqhs.github.io%2F2019%2F05%2Ftext-classification-scikit-learn%2F" aria-label="Share on Reddit">
          <i class="fab fa-reddit" aria-hidden="true"></i><span>Share on Reddit</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>


    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-times"></i>
    </div>
    
      <img id="about-card-picture" src="https://cdn.jsdelivr.net/gh/lijqhs/cdn@1.2/img/icons/plane-icon.png" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">aaron</h4>
    
      <div id="about-card-bio">random notes</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        software engineer, FRM
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker-alt"></i>
        <br/>
        canada
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://lijqhs.github.io/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/highlight.min.js" integrity="sha512-z+/WWfyD5tccCukM4VvONpEtLmbAm5LDu7eKiyMQJ9m7OfPEDL7gENyDRL3Yfe8XAuGsS2fS4xSMnl6d30kqGQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha512-uURl+ZXMBrF4AwGaWmEetzrd+J5/8NRkWAvJx5sbPSSuOb0bZLqf+tOzniObO00BjHa/dD7gub9oCGMLPQHtQA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>


<script src="https://lijqhs.github.io/js/script-yqzy9wdlzix4lbbwdnzvwx3egsne77earqmn73v9uno8aupuph8wfguccut.min.js"></script>


  
    <script async crossorigin="anonymous" defer integrity="sha512-gE8KAQyFIzV1C9+GZ8TKJHZS2s+n7EjNtC+IMRn1l5+WYJTHOODUM6JSjZhFhqXmc7bG8Av6XXpckA4tYhflnw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/apache.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-EWROca+bote+7Oaaar1F6y74iZj1r1F9rm/ly7o+/FwJopbBaWtsFDmaKoZDd3QiGU2pGacBirHJNivmGLYrow==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/go.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-GDVzAn0wpx1yVtQsRWmFc6PhJiLBPdUic+h4GWgljBh904O3JU10fk9EKNpVyIoPqkFn54rgL2QBG4BmUTMpiQ==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/http.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-UgZlma8NzkrDb/NWgmLIcTrH7i/CSnLLDRFqCSNF5NGPpjKmzyM25qcoXGOup8+cDakKyaiTDd7N4dyH4YT+IA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/less.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-lot9koe73sfXIrUvIPM/UEhuMciN56RPyBdOyZgfO53P2lkWyyXN7J+njcxIIBRV+nVDQeiWtiXg+bLAJZDTfg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/nginx.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-Zd3e7XxHP00TD0Imr0PIfeM0fl0v95kMWuhyAS3Wn1UTSXTkz0OhtRgBAr4JlmADRgiXr4x7lpeUdqaGN8xIog==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/puppet.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-qtqDO052iXMSP+5d/aE/jMtL9vIIGvONgTJziC2K/ZIB1yEGa55WVxGE9/08rSQ62EoDifS9SWVGZ7ihSLhzMA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/scss.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-1NmkjnEDnwwwcu28KoQF8vs3oaPFokQHbmbtwGhFfeDsQZtVFI8zW2aE9O8yMYdpdyKV/5blE4pSWw4Z/Sv97w==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/stylus.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-B2wSfruPjr8EJL6IIzQr1eAuDwrsfIfccNf/LCEdxELCgC/S/ZMt/Uvk80aD79m7IqOqW+Sw8nbkvha20yZpzg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/swift.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-28oDiQZGKUVN6wQ7PSLPNipOcmkCALXKwOi7bnkyFf8QiMZQxG9EQoy/iiNx6Zxj2cG2SbVa4dXKigQhu7GiFw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/yaml.min.js"></script>
  


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      CommonHTML: { linebreaks: { automatic: true } },
      tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
      messageStyle: 'none'
    });
  </script>



    
  </body>
</html>

